\section*{Regresja}
\subsection*{Regresja liniowa}

Dla równania danego wzorem $y = ax + b$, współczynniki prostej regresji
dla zaobserwowanych danych są dane wzorami

\begin{equation*}
    a = \frac{\sum_{i=1}^{n} 
    (x_i - \overline{x})
    (y_i - \overline{y})}
    {\sum_{i=1}^{n} (x_i - \overline{x})^2}
\end{equation*}

\vspace{1em}

\begin{equation*}
    b = \overline{y} - a \overline{x}
\end{equation*}

gdzie

$\overline{x}$ - średnia z $x$

$\overline{y}$ - średnia z $y$

$x_i$, $y_i$ - zaobserwowane dane

\subsection*{Regresja liniowa wilowymiarowa}

\begin{equation*}
    X \cdot a = y - e
\end{equation*}

\begin{equation*}
    X = \begin{bmatrix}
            1 & x_{1,1} & x_{2,1} &\hdots& x_{K,1}\\
            1 & x_{1,2} & x_{2,2} &\hdots& x_{K,2}\\
            1 & x_{1,3} & x_{2,3} &\hdots& x_{K,3}\\
            \vdots & \vdots & \vdots & \ddots & \vdots\\
            1 & x_{1,2} & x_{2,2} &\hdots& x_{K,N}\\
    \end{bmatrix}, 
a = \begin{bmatrix}
    a_0 \\ a_1 \\ a_2 \\ \vdots \\a_K
\end{bmatrix},\ \
y = \begin{bmatrix}
    y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_N
\end{bmatrix},\ \
e = \begin{bmatrix}
    e_1\\e_2\\e_3\\\vdots\\e_N
\end{bmatrix}
\end{equation*}

Aby obliczyć macierz $a$, należy zastosować macierze pseudolosową
według równania

\begin{equation*}
a = ( X^T \cdot X)^{-1} \cdot X^T \cdot y
\end{equation*}

\subsection*{Regresja nieliniowa}

\begin{equation*}
    X \cdot a = y - e
\end{equation*}

\begin{equation*}
    \begin{bmatrix}
            1 & g(x_1)\\
            1 & g(x_2)\\
            1 & g(x_3)\\
            \vdots & \vdots \\ 
            1 & g(x_N) 
    \end{bmatrix}
\cdot \begin{bmatrix}
    a_0 \\ a_1 
\end{bmatrix}
 = \begin{bmatrix}
    y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_N
\end{bmatrix} - \begin{bmatrix}
    e_1\\e_2\\e_3\\\vdots\\e_N
\end{bmatrix}
\end{equation*}

Aby obliczyć macierz $a$, należy zastosować macierze pseudolosową
według równania

\begin{equation*}
a = ( X^T \cdot X)^{-1} \cdot X^T \cdot y
\end{equation*}